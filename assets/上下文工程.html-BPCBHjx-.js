import{_ as t,c as a,a as n,b as p,d as i,o as s}from"./app-tQFyOY_y.js";const r={};function o(l,e){return s(),a("div",null,[e[0]||(e[0]=n("h1",{id:"上下文工程-——-解锁大模型真正潜力的关键",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#上下文工程-——-解锁大模型真正潜力的关键"},[n("span",null,"上下文工程 —— 解锁大模型真正潜力的关键")])],-1)),p(" more "),e[1]||(e[1]=i('<h2 id="上下文工程解决什么问题" tabindex="-1"><a class="header-anchor" href="#上下文工程解决什么问题"><span>上下文工程解决什么问题</span></a></h2><p>现阶段，基于 RAG 想提高生成式问答效果，简单地 “检索 - 拼接 - 生成” 往往并不能得到最优结果。可能会遇到：</p><ul><li><p>检索到的信息不准确或与问题无关。</p></li><li><p>即使检索到了相关信息，LLM 却忽略了它，依然依赖自身知识产生幻觉。</p></li><li><p>上下文太长，导致 LLM 无法关注到关键信息，或者因超过令牌限制而被截断。</p></li></ul><p>此时，就需要上下文工程来解决这些问题。</p><p>上下文工程是一门设计和优化输入给 LLM 的上下文信息的艺术与科学，旨在最大化 LLM 的推理能力和输出质量。</p><h2 id="上下文工程所包含的范围" tabindex="-1"><a class="header-anchor" href="#上下文工程所包含的范围"><span>上下文工程所包含的范围</span></a></h2><p>一句话，只要是模型生成回答之前所看到的一切信息，都是上下文工程的范畴。</p><figure><img src="https://cloud.bytelighting.cn/f/myPh1/context-engineering.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>其核心工作贯穿以下流程：</p><p><strong>1. 检索前的数据准备（知识库层面）</strong></p><ul><li><p><strong>分块（Chunking）</strong></p><p>如何将长文档切割成更小的片段至关重要。块太大可能包含多主题干扰信息，太小则可能丢失关键上下文。工程师需要根据文档类型（如MD文档、PDF表格、代码）调整块大小和重叠（Overlap）策略。</p></li><li><p><strong>数据清洗与增强</strong></p><p>清除无关内容（页眉、页脚）、标准化格式、为文本添加元数据（如标题、发布日期、部门），这些元数据可以极大提升检索的精准度。</p></li><li><p><strong>选择嵌入模型（Embedding Model）</strong></p><p>不同的模型在不同领域和语言上表现各异。为特定领域微调嵌入模型或选择专有模型，可以显著提升检索相关性。</p></li></ul><p><strong>2. 检索中的优化（查询与搜索层面）</strong></p><ul><li><p><strong>查询重写/扩展（Query Reformulation/Expansion）</strong></p><p>用户的原始查询可能很模糊。使用 LLM 对查询进行重写、扩展同义词或生成假设性答案（HyDE），可以大幅提升检索效果。</p></li><li><p><strong>检索策略</strong></p><p>除了简单的相似性搜索，还可以融合关键词搜索（BM25）进行混合搜索（Hybrid Search），兼顾语义匹配和精确术语匹配。高级技术如重新排序（Re-ranking）模型，可以对初步检索结果进行二次精排，将最相关的结果排在前面。</p></li></ul><p><strong>3. 生成前的上下文构建（提示词层面）—— 这是上下文工程的核心</strong></p><ul><li><p><strong>上下文压缩与摘要</strong></p><p>检索到的多个文档片段可能包含冗余信息。可以使用 LLM 先对这些片段进行摘要或去重，只将最精炼的信息放入上下文，节省宝贵的令牌。</p></li><li><p><strong>结构化与排序</strong></p><p>将检索到的上下文以清晰、有条理的方式呈现给 LLM。例如，按相关性排序，或使用明确的章节标题（如 “## 相关文档1：... ## 相关文档2：...”），帮助 LLM 更好地理解和利用这些信息。</p></li><li><p><strong>设计系统提示（System Prompt）</strong></p><p>这是上下文工程的精髓。系统提示用于明确指导 LLM 如何利用上下文。</p></li><li><p><em>糟糕的提示</em></p><p>“请根据以下文档回答问题。”</p></li><li><p><em>工程化的提示</em></p><p>“你是一个专业的客服助手。请严格根据提供的参考文档来回答问题。如果文档中的信息不足以回答问题，请明确回答 ‘根据已有信息无法回答该问题’，切勿编造信息。你的回答需清晰引用文档来源。参考文档如下：...”</p></li></ul><p>通过上述精细化的操作，上下文工程确保了注入 LLM 的信息是 <strong>高相关、高质量、易理解</strong> 的，从而最终引导 LLM 生成 <strong>更准确、更可靠、更符合要求</strong> 的答案。</p><h2 id="上下文工程落地的策略" tabindex="-1"><a class="header-anchor" href="#上下文工程落地的策略"><span>上下文工程落地的策略</span></a></h2><figure><img src="https://cloud.bytelighting.cn/f/YOLu8/General categories of context engineering.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>上面四个落地策略来自 Langchain 发布的一篇博客文章，归纳四个词就是 “<strong>写入 - 筛选 - 压缩 - 隔离</strong>”，有点像 SQL 的增-删-改-查。</p><p>本质上，我们现在的调优工作，其实都在上下文工程这个范畴，这里面涉及到的 Scratchpads、Memories、Tools、Knowledge、Context Summarization、Multi-agent、Context 等。</p><p>再回归到问题的本质，如果只是需要提高大语言模型回答问题的准确率和质量，engineering 这里面有非常大的想象空间，RAG 只是一个 context engineering 非常粗糙的一个工程方案。</p><p>Andrej Karpathy 一个推特火了一个新词，就能让这个工作成为业界一个追逐范式，并且发展成一个工程学科，这就是业界影响力！</p><h2 id="上下文工程不等同于上下文" tabindex="-1"><a class="header-anchor" href="#上下文工程不等同于上下文"><span>上下文工程不等同于上下文</span></a></h2><p><strong>两者的目的都是通过引入额外的、动态的信息，使系统的输出与当前情境更相关、更精准。</strong></p><p>在我们 MCP 应用中，目前我们一个稍微复杂点的问题，MCP 最多能调 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>12</mn><mo>−</mo><mn>15</mn></mrow><annotation encoding="application/x-tex">12-15</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">12</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">15</span></span></span></span> 个 Tools，但实际调用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3</span></span></span></span> 个 Tools 就能解决这个问题。一些技术报告也实验证明了更多的工具、更多的补充信息、更长的上下文并不一定会产生更好的响应。上下文过载可能会导致智能体以意想不到的方式失败。上下文可能会变得有害、分散注意力、令人困惑或产生冲突。</p><p>在我们 A2A 应用中，智能体之前也是依赖上下文来收集信息，但综合发现一旦涉及到多轮对话上下文，动作智能体之间的关系就容易出错，因为一旦涉及到相互协作和相互依赖，信息之间就会出现错乱。</p><p>我个人理解，在比较高级一点的应用，这两项技术应该是相互融合的，一方面要让生成的回答更 <strong>准确、可信、相关；另一方面，追求个性化、情境化的智能输出</strong>。</p><h2 id="上下文工程前瞻思考" tabindex="-1"><a class="header-anchor" href="#上下文工程前瞻思考"><span>上下文工程前瞻思考</span></a></h2><p>如题，Context Engineering 是解锁大模型真正潜力的关键，未来落地落地思考会暂时会围绕以下两点去展开：</p><p><strong>1）大语言模型（LLM）作为智能体的大脑，那上下文工程就是这个大脑的 “外脑”，它未来要自主决定何时需要检索、检索什么、如何根据初步结果进行下一步操作，这一定是自动化的。</strong></p><p><strong>2）突破 RAG 系统限制，追求对上下文的深度加工，而 RAG 只提供了 “检索” 这一种获取方式。加工包括：总结、翻译、格式化、过滤、排序、压缩等，远非简单的 “检索并拼接”。</strong></p><p>如今在大模型时代，提示工程（Prompt Engineering）已然不能完全解放人工写提示过程，但上下文工程（Context Engineering）是有可能彻底告别人工调优的。</p><hr><p>参考资料：</p><p>[1] The New Skill in AI is Not Prompting, It&#39;s Context Engineering (<a href="https://www.philschmid.de/context-engineering" target="_blank" rel="noopener noreferrer">https://www.philschmid.de/context-engineering</a>)</p><p>[2] Context Engineering (<a href="https://blog.langchain.com/context-engineering-for-agents/" target="_blank" rel="noopener noreferrer">https://blog.langchain.com/context-engineering-for-agents/</a>)</p><p>[3] The rise of &quot;context engineering&quot; (<a href="https://blog.langchain.com/the-rise-of-context-engineering/" target="_blank" rel="noopener noreferrer">https://blog.langchain.com/the-rise-of-context-engineering/</a>)</p>',37))])}const c=t(r,[["render",o],["__file","上下文工程.html.vue"]]),m=JSON.parse('{"path":"/computer/llm/application/%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B.html","title":"上下文工程 —— 解锁大模型真正潜力的关键","lang":"zh-CN","frontmatter":{"category":["LLM 应用"],"tag":["Prompt"],"comment":true,"head":[["meta",{"property":"og:url","content":"https://blog.bytelighting.cn/computer/llm/application/%E4%B8%8A%E4%B8%8B%E6%96%87%E5%B7%A5%E7%A8%8B.html"}],["meta",{"property":"og:site_name","content":"ByteLighting"}],["meta",{"property":"og:title","content":"上下文工程 —— 解锁大模型真正潜力的关键"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://cloud.bytelighting.cn/f/myPh1/context-engineering.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-10-06T15:53:40.000Z"}],["meta",{"property":"article:tag","content":"Prompt"}],["meta",{"property":"article:modified_time","content":"2025-10-06T15:53:40.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"上下文工程 —— 解锁大模型真正潜力的关键\\",\\"image\\":[\\"https://cloud.bytelighting.cn/f/myPh1/context-engineering.png\\",\\"https://cloud.bytelighting.cn/f/YOLu8/General%20categories%20of%20context%20engineering.png\\"],\\"dateModified\\":\\"2025-10-06T15:53:40.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"BraumAce\\",\\"url\\":\\"https://blog.bytelighting.cn/article\\"}]}"]]},"headers":[{"level":2,"title":"上下文工程解决什么问题","slug":"上下文工程解决什么问题","link":"#上下文工程解决什么问题","children":[]},{"level":2,"title":"上下文工程所包含的范围","slug":"上下文工程所包含的范围","link":"#上下文工程所包含的范围","children":[]},{"level":2,"title":"上下文工程落地的策略","slug":"上下文工程落地的策略","link":"#上下文工程落地的策略","children":[]},{"level":2,"title":"上下文工程不等同于上下文","slug":"上下文工程不等同于上下文","link":"#上下文工程不等同于上下文","children":[]},{"level":2,"title":"上下文工程前瞻思考","slug":"上下文工程前瞻思考","link":"#上下文工程前瞻思考","children":[]}],"git":{"createdTime":1759653412000,"updatedTime":1759766020000,"contributors":[{"name":"BraumAce","email":"siyuan.peng@foxmail.com","commits":3}]},"readingTime":{"minutes":6.03,"words":1810},"filePathRelative":"computer/llm/application/上下文工程.md","localizedDate":"2025年10月5日","excerpt":"\\n"}');export{c as comp,m as data};
