import{_ as e,c as a,d as s,b as l,o as t}from"./app-wJw7WjUK.js";const n={};function h(d,i){return t(),a("div",null,[i[0]||(i[0]=s('<h1 id="如何使用-linux-下的日志分析工具" tabindex="-1"><a class="header-anchor" href="#如何使用-linux-下的日志分析工具"><span>如何使用 Linux 下的日志分析工具</span></a></h1><p>对于后端开发来说，熟练掌握 Linux 的日志分析命令是基本功，整理了一些基于 <code>tail</code>、<code>less</code>、<code>grep</code>、<code>sed</code>、<code>awk</code> 的日志查询场景，帮助快速定位问题。</p>',2)),l(" more "),i[1]||(i[1]=s(`<h2 id="tail" tabindex="-1"><a class="header-anchor" href="#tail"><span>tail</span></a></h2><div class="hint-container info"><p class="hint-container-title">作用</p><p>“实时监控器”，用来盯着日志正在发生什么。</p><p>主要用于查看文件的最后部分内容（默认显示最后 10 行）。</p><p>在日志分析中，它最强大的功能是 <strong>实时跟踪</strong> 文件的动态增长。</p></div><p>很多新手习惯用 <code>cat</code>，但对于大文件，<code>cat</code> 会导致屏幕刷屏，还容易把终端卡死。<code>tail</code> 才是实时监控的神器。</p><ul><li><strong>真实场景 A：服务发版启动监控</strong></li></ul><p>每次发版重启服务时，我们都需要确认 Spring Boot 是否启动成功，或者有没有初始化报错。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># -f (follow)：实时追加显示文件尾部内容</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">tail</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> logs/application.log</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><strong>真实场景 B：配合测试复现 Bug</strong></li></ul><p>测试同学说：我现在点一下按钮，你看看后台有没有报错。</p><p>此时不需要看历史日志，只需要盯着最新的输出。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># -n 200 -f：只看最后 200 行，并保持实时刷新，避免被历史日志干扰</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">tail</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -n 200 -f</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> logs/application.log</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="less" tabindex="-1"><a class="header-anchor" href="#less"><span>less</span></a></h2><div class="hint-container info"><p class="hint-container-title">作用</p><p>“阅读器”，用来翻阅和查找大文件里的内容。</p><ul><li>高效阅读：按需加载，打开大文件极快。</li><li>交互式导航：支持上下滚动、翻页，以及在文件内搜索。</li><li>查看特定位置：可以快速跳转到文件末尾或指定行号。</li></ul></div><p>如果需要查看之前的日志，推荐使用 <code>less</code>。不同于 <code>vim</code> 会一次性加载整个文件占用大量内存，<code>less</code> 是按需加载，打开几个 G 的文件也极其流畅，且支持前后翻页、搜索。</p><ul><li><strong>真实场景：追查某笔客诉订单</strong></li></ul><p>运营反馈：刚才 10 点左右，订单号 <code>ORD12345678</code> 支付失败了。</p><p>你需要从日志末尾开始，往前反向查找这个订单号。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">less</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> logs/application.log</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><strong>进入界面后的操作流：</strong></p><ol><li><code>Shift + G</code>： 先跳到日志最末尾（因为报错通常发生在最近）。</li><li><code>?ORD12345678</code>： 输入问号 + 订单号，<strong>向上反向搜索</strong>。</li><li><code>n</code>：如果当前这行不是关键信息，按 <code>n</code> 继续向上找上一次出现的位置。</li><li><code>Shift + F</code>： 如果看着看着，日志又更新了，按这个组合键可以让 less 进入类似 <code>tail -f</code> 的实时滚动模式；按 <code>Ctrl + C</code> 退回浏览模式。</li></ol><h2 id="grep" tabindex="-1"><a class="header-anchor" href="#grep"><span>grep</span></a></h2><div class="hint-container info"><p class="hint-container-title">作用</p><p>“过滤器”，帮你从海量日志里捞出包含特定关键词的行。</p><p>最强大的文本搜索工具，它能使用正则表达式搜索文本，并打印匹配的行。</p></div><p><code>grep</code> 是最常用的搜索命令，但在实际业务中，简单的关键词搜索往往不够用。</p><ul><li><strong>真实场景 A：还原报错现场（重点）</strong></li></ul><p>只看到 <code>NullPointerException</code> 这一行往往无法定位问题，我们需要知道 <u>报错前</u> 的请求参数是什么，<u>报错后</u> 的堆栈信息是什么。</p><p>此时必须配合 <code>-C</code> (Context) 参数。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 搜索异常关键字，并显示该行 &quot;前后各 20 行&quot;</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">grep</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -C 20 </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;NullPointerException&quot;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> logs/application.log</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><strong>真实场景 B：全链路追踪 TraceId</strong></li></ul><p>微服务我们通常会通过 <code>TraceId</code> 串联请求。日志文件可能发生了滚动（Rolling），变成了 <code>app.log</code>、<code>app.log.1</code>、<code>app.log.2</code>。</p><p>我们需要在所有日志文件中搜索同一个 TraceId。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 搜索当前目录下所有以 app.log 开头的文件</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">grep </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">&quot;TraceId-20251219001&quot;</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> logs/app.log*</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><strong>真实场景 C：统计异常频次</strong></li></ul><p>老板问：“Redis 超时异常今天到底发生了多少次？是偶发还是大规模？”</p><p>不需要数数，直接统计行数。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># -c (count)：只统计匹配的行数</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">grep</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -c </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;RedisConnectionException&quot;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> logs/application.log</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><strong>真实场景 D：排除干扰噪音</strong></li></ul><p>排查问题时，日志里充斥着大量无关的 <code>INFO</code> 心跳日志或健康检查日志，严重干扰视线。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># -v (invert)：显示不包含 &quot;HealthCheck&quot; 的所有行</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">grep</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -v </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;HealthCheck&quot;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> logs/application.log</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="sed" tabindex="-1"><a class="header-anchor" href="#sed"><span>sed</span></a></h2><div class="hint-container info"><p class="hint-container-title">作用</p><p>“编辑器”，用来修改、替换或删除文本内容。</p><p>主要用来对文本进行自动化的编辑操作，如替换、删除、插入。</p><p>它以行为单位处理数据，非常适合批量修改日志格式或清理数据。</p></div><p>有时候日志非常大，例如有 10GB，<code>grep</code> 搜出来的内容依然过多。如果我们明确知道生产事故发生在 <u>14:00 到 14:05</u> 之间，该怎么办？</p><p>下载整个日志不现实，<code>sed</code> 可以帮我们把这段时间的日志单独切出来，保存成一个小文件慢慢分析。</p><ul><li><strong>真实场景：导出事故时间窗口的日志</strong></li></ul><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 语法：sed -n &#39;/开始时间/,/结束时间/p&#39; 源文件 &gt; 目标文件</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 注意：时间格式必须和日志里的格式完全一致</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sed</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -n </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;/2025-12-19 14:00/,/2025-12-19 14:05/p&#39;</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> logs/application.log</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> &gt; </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">error_segment.log</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这样你就得到了一个只有几 MB 的 <code>error_segment.log</code>，这时候再下载到本地分析，或者发给同事，都非常方便。</p><h2 id="awk" tabindex="-1"><a class="header-anchor" href="#awk"><span>awk</span></a></h2><div class="hint-container info"><p class="hint-container-title">作用</p><p>“编程语言”，用来处理结构化数据、提取列和做统计。</p><p><code>awk</code> 其实是一门小型编程语言。它擅长处理结构化文本（如按列排列的日志），可以像 SQL 一样对数据进行切片、统计和计算。</p></div><p><code>awk</code> 擅长处理列数据，对于格式规范的日志，如 Nginx 访问日志、Apache 日志，它可以直接在服务器上生成简报。</p><ul><li><strong>真实场景 A：遭到攻击，查找恶意 IP</strong></li></ul><p>服务突然报警 CPU 飙升，怀疑遭到 CC 攻击或爬虫抓取，我们需要分析 Nginx 日志，找出访问量最高的 IP。</p><p>假设日志格式第一列是 IP：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 1. awk &#39;{print $1}&#39;：提取第一列（IP）</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 2. sort：排序，把相同的 IP 排在一起</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 3. uniq -c：去重并统计每个 IP 出现的次数</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 4. sort -nr：按次数(n)倒序(r)排列</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 5. head -n 10：取前 10 名</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">awk </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">&#39;{print $1}&#39;</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> access.log</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> | </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sort</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> | </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">uniq</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -c</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> | </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sort</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -nr</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> | </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">head</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -n 10</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><strong>真实场景 B：找出响应最慢的接口</strong></li></ul><p>Nginx 日志中通常记录了响应时间，假设在最后一列，我们想把响应时间超过 1 秒的请求找出来。</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># $NF 代表最后一列</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 打印所有响应时间大于 1 秒的 URL（假设 URL 在第 7 列）</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">awk </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">&#39;$NF &gt; 1.000 {print $7, $NF}&#39;</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> access.log</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,54))])}const p=e(n,[["render",h],["__file","如何使用Linux下的日志分析工具.html.vue"]]),o=JSON.parse('{"path":"/program/sundry/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Linux%E4%B8%8B%E7%9A%84%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7.html","title":"如何使用 Linux 下的日志分析工具","lang":"zh-CN","frontmatter":{"category":["杂项"],"tag":["工作笔记"],"comment":true,"description":"对于后端开发来说，熟练掌握 Linux 的日志分析命令是基本功，整理了一些基于 tail、less、grep、sed、awk 的日志查询场景，帮助快速定位问题。","head":[["meta",{"property":"og:url","content":"https://blog.bytelighting.cn/program/sundry/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Linux%E4%B8%8B%E7%9A%84%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7.html"}],["meta",{"property":"og:site_name","content":"ByteLighting"}],["meta",{"property":"og:title","content":"如何使用 Linux 下的日志分析工具"}],["meta",{"property":"og:description","content":"对于后端开发来说，熟练掌握 Linux 的日志分析命令是基本功，整理了一些基于 tail、less、grep、sed、awk 的日志查询场景，帮助快速定位问题。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-12-28T10:14:25.000Z"}],["meta",{"property":"article:tag","content":"工作笔记"}],["meta",{"property":"article:modified_time","content":"2025-12-28T10:14:25.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"如何使用 Linux 下的日志分析工具\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-12-28T10:14:25.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"BraumAce\\",\\"url\\":\\"https://blog.bytelighting.cn/article\\"}]}"]]},"headers":[{"level":2,"title":"tail","slug":"tail","link":"#tail","children":[]},{"level":2,"title":"less","slug":"less","link":"#less","children":[]},{"level":2,"title":"grep","slug":"grep","link":"#grep","children":[]},{"level":2,"title":"sed","slug":"sed","link":"#sed","children":[]},{"level":2,"title":"awk","slug":"awk","link":"#awk","children":[]}],"git":{"createdTime":1766916865000,"updatedTime":1766916865000,"contributors":[{"name":"BraumAce","email":"siyuan.peng@foxmail.com","commits":1}]},"readingTime":{"minutes":5.5,"words":1649},"filePathRelative":"program/sundry/如何使用Linux下的日志分析工具.md","localizedDate":"2025年12月28日","excerpt":"\\n<p>对于后端开发来说，熟练掌握 Linux 的日志分析命令是基本功，整理了一些基于&nbsp;<code>tail</code>、<code>less</code>、<code>grep</code>、<code>sed</code>、<code>awk</code>&nbsp;的日志查询场景，帮助快速定位问题。</p>\\n","autoDesc":true}');export{p as comp,o as data};
