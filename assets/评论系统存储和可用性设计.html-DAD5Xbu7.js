import{_ as t,c as a,a as i,b as s,d as n,o as p}from"./app-DRTkYq_m.js";const l={};function r(c,e){return p(),a("div",null,[e[0]||(e[0]=i("h1",{id:"评论系统和可用性设计",tabindex:"-1"},[i("a",{class:"header-anchor",href:"#评论系统和可用性设计"},[i("span",null,"评论系统和可用性设计")])],-1)),s(" more "),e[1]||(e[1]=n('<blockquote><p>转载自<strong>stormspirit</strong>，原文链接：<a href="https://mp.weixin.qq.com/s/N1UdNS4V_5DOLeHi6uzWRQ" target="_blank" rel="noopener noreferrer">评论系统和可用性设计</a></p></blockquote><h2 id="存储设计" tabindex="-1"><a class="header-anchor" href="#存储设计"><span>存储设计</span></a></h2><h3 id="数据表设计" tabindex="-1"><a class="header-anchor" href="#数据表设计"><span>数据表设计</span></a></h3><p>先看一张 b 站的评论图：</p><figure><img src="https://cloud.braumace.cn/f/XPjS0/0801_1.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>如上图所示，主评论下面有子评论，子评论之间也可以互相评论，并且评论之间是通过赞数进行排序的。</p><p>数据表设计：</p><figure><img src="https://cloud.braumace.cn/f/xZGFl/0801_2.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>如上图，评论系统分为三张表。</p><p><strong>comment_subject</strong></p><p>评论主题表。一个主题可能是一个视频稿件、一篇文章等。分成了 50 张表。自增 id 做主键。</p><p><code>obj_id</code> 是主题 id， <code>obj_type</code> 是主题类型。</p><p>另外还保存了一些计数字段，比如评论总数等。这样做是为了避免每次需要统计总数时都要做一次 <code>select count(*)</code> ，这样效率很低，所以直接每次新增评论的时候就把相应字段 +1 即可。</p><p><strong>comment_index</strong></p><p>评论索引表。主要存的是评论的 id 与评论主题的对应关系，以及该评论的一些相关信息，比如是不是根评论、评论楼层，评论总数等。分成了 200 张表。使用自增 id 做主键，主键 id 就是评论 id。</p><p>root 是该评论的根评论 id，比如上面评论图红框里的就是根评论。不为 0 就是回复的评论，为 0 就是根评论。</p><p>parent 是这个评论的父评论，也就是它是回复哪条评论的，如果为 0 那这个评论就是根评论。</p><p>其他的都是一些统计信息等等。</p><p><strong>comment_content</strong></p><p>评论内容表。主要存的是评论实际内容。分成了 200 张表。</p><p>它直接使用 <code>comment_id</code>（对应的就是 comment_index 表的 id ）作为主键，这样的好处是：</p><ul><li><p>表都有主键，即 cluster index，是物理组织形式存放的，comment_content 没有 id，是为了减少一次二级索引查找，直接基于主键检索，同时 comment_id 在写入要尽可能的顺序自增。</p><p>意思是从 comment_index 表里捞出来一堆 <code>comment_id</code> ，那就可以直接通过这些 <code>comment_id</code> 作为主键去查询 comment_content 表了。如果 content 表还有自己的自增主键的话，那么通过 <code>comment_id</code> 去查必然需要先查到自己的主键 id ，然后再通过 id 去查到这一行数据，多了一步操作。</p></li><li><p>索引、内容分离，方便 mysql datapage 缓存更多的 row，如果和 content 耦合，会导致更大的 IO。长远来看 content 信息可以直接使用 KV storage 存储。比如 Rocks DB 等。</p></li></ul><p>这也是一种 <strong>「索引内容分离」</strong> 的设计思想。</p><p><strong>写数据</strong></p><p>事务更新 comment_subject，comment_index，comment_content 三张表，其中 content 属于非强制需要一致性考虑的。可以先写入 content，之后事务更新其他表。即便 content 先成功，后续失败仅仅存在一条 ghost 数据。</p><p><strong>读数据</strong></p><p>基于 <code>obj_id</code> + <code>obj_type</code> 在 comment_index 表找到根评论列表，比如：</p><div class="language-sql line-numbers-mode" data-highlighter="shiki" data-ext="sql" data-title="sql" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">select</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> id </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> comment_index </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">where</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> obj_id </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;x&#39;</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> and</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> obj_type </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;y&#39;</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> and</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> root</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> =</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 0</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> ORDER BY</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> floor;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>对于二级的子楼层，由于一般只查询 3 层子楼层：</p><div class="language-sql line-numbers-mode" data-highlighter="shiki" data-ext="sql" data-title="sql" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">select</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> id </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> comment_index </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">where</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> parent/</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">root</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> (上面查询出来的 id) </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">and</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> floor </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&lt;=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 3</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> order by</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> floor;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>之后根据 comment_index 的 id 字段捞出 comment_content 的评论内容。</p><p>因为产品形态上只存在 <strong>「二级列表」</strong>，因此只需要迭代查询两次即可。对于嵌套层次多的，产品上，可以通过二次点击支持。</p><p>这种迭代查询的方式也可以直接用图数据库来实现，可能更好，比如 DGraph、HugeGraph 类似的图存储思路。</p><h3 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h3><p>主题一张表，评论索引与评论内容分开两张表来存，表里有一些统计字段，避免每次都重新统计。内容表的主键直接使用评论 id，避免使用评论 id 查询还需要回表。评论内容可以使用 kv 数据库。写入时可以先写评论内容表，评论索引表和主题表用一个事务更新。</p><h3 id="缓存设计" tabindex="-1"><a class="header-anchor" href="#缓存设计"><span>缓存设计</span></a></h3><figure><img src="https://cloud.braumace.cn/f/vwkFE/0801_3.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="https://cloud.braumace.cn/f/APPIE/0801_4.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="https://cloud.braumace.cn/f/yg8T1/0801_5.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>comment_subject_cache</strong></p><p>对应主题的缓存，value 使用 protobuf 序列化的方式存入。</p><p><strong>comment_index_cache</strong></p><p>使用 redis sortedset 进行索引的缓存。key 是主题 id + 主题 type + 排序方式， member 就是评论 id，score 就是根据各种要素排序的得分。这样就可以根据某个主题查询，得到排序过后的评论 id 列表。然后就可以通过评论 id 列表去批量查询评论内容了。</p><div class="hint-container tip"><p class="hint-container-title">提示</p><p>索引即数据的组织顺序，而非数据内容。参考过百度的贴吧，他们使用自己研发的拉链存储来组织索引，我认为 mysql 作为主力存储，利用 redis 来做加速完全足够，因为 cache miss 的构建，我们前面讲过使用 kafka 的消费者中处理，预加载少量数据，通过增量加载的方式逐渐预热填充缓存，而 redis sortedset skiplist 的实现，可以做到 O(logN) + O(M) 的时间复杂度，效率很高。</p></div><p>sorted set 是要增量追加的，因此必须判定 key 存在，才能 zdd。</p><p><strong>comment_content_cache</strong></p><p>对应评论内容数据，使用 protobuf 序列化的方式存入。</p><p>缓存使用增量加载 + lazy 加载模式，也就是在查询第一页的时候会将后两页评论数据也一起加载进缓存。可以使用 kafka 进行缓存的异步构建。</p><h2 id="可用性设计" tabindex="-1"><a class="header-anchor" href="#可用性设计"><span>可用性设计</span></a></h2><h3 id="缓存穿透" tabindex="-1"><a class="header-anchor" href="#缓存穿透"><span>缓存穿透</span></a></h3><p><strong>singleflight</strong></p><figure><img src="https://cloud.braumace.cn/f/9X8Ur/0801_6.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>对于热门的主题，如果存在缓存穿透的情况，会导致大量的同进程、跨进程的数据回源到存储层，可能会引起存储过载的情况，如何只交给同进程内，一个人去做加载存储？</p><p>使用归并回源的思路 singleflight，singleflight 的原理可以看这篇文章 Go并发编程(十二) Singleflight。</p><p>同进程只交给一个人去获取 mysql 数据，然后批量返回。</p><p>同时这个租约 owner 投递一个 kafka 消息，做该 key 的 cache build 的操作。这样可以大大减少查询 mysql 的压力，以及大量透穿导致的密集写 kafka 的问题（如果不这么做那么会有很多的进程向 kafka 发送 cache rebuild 的指令，然后它们都会去 mysql 里查询数据写缓存）。</p><p>更进一步的，后续连续的请求，仍然可能会短时 cache miss，我们可以在进程内设置一个过期时间为 5 秒的 short-lived flag，标记最近有一个人投递了同一个 key 的 cache rebuild 的消息，如果有这个 flag ，那么相同的 kafka 消息直接 drop 而不会再去查 mysql 构建缓存，这样 mysql 的压力更小。</p><p>再进一步，可以在 comment-job 内存里设置一个过期时间很短的比如 5 秒的 LRU cache， 有一个线程去 mysql 里查到了数据就更新这个缓存，然后其他的线程直接从这个缓存里拿数据即可，这样就不用重复去 mysql 里查了，同样减少了对 mysql 的查询压力。</p><p>一般不需要使用分布式锁，实现起来太复杂而且很容易出错。</p><h3 id="热点" tabindex="-1"><a class="header-anchor" href="#热点"><span>热点</span></a></h3><p>流量热点是因为突然热门的主题，被高频次的访问，因为底层的 cache 设计，一般是按照主题 key 进行一致性 hash 来进行分片，但是热点 key 一定命中某一个节点，这时候 remote cache 可能会变为瓶颈，因此做 cache 的升级 local cache 是有必要的，我们一般使用**「单进程自适应发现热点」**的思路，附加一个短时的 ttl local cache，可以在进程内吞掉大量的读请求。</p><p>在内存中使用 hashmap 统计每个 key 的访问频次，这里可以使用滑动窗口统计（如下图），即每个窗口中，维护一个 hashmap，之后统计所有未过期的 bucket，汇总所有 key 的数据。</p><p>之后使用小顶堆计算 TopK 的数据，自动进行热点识别。把 TopK 的 key 统一 load 到本地缓存。</p><figure><img src="https://cloud.braumace.cn/f/w15Ck/0801_7.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>',64))])}const h=t(l,[["render",r],["__file","评论系统存储和可用性设计.html.vue"]]),d=JSON.parse('{"path":"/architecture/system-design/comment/%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F%E5%AD%98%E5%82%A8%E5%92%8C%E5%8F%AF%E7%94%A8%E6%80%A7%E8%AE%BE%E8%AE%A1.html","title":"评论系统和可用性设计","lang":"zh-CN","frontmatter":{"date":"2024-08-01T00:00:00.000Z","category":["系统设计"],"tag":["评论系统"],"reprint":true,"head":[["meta",{"property":"og:url","content":"https://blog.braumace.cn/architecture/system-design/comment/%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F%E5%AD%98%E5%82%A8%E5%92%8C%E5%8F%AF%E7%94%A8%E6%80%A7%E8%AE%BE%E8%AE%A1.html"}],["meta",{"property":"og:site_name","content":"ByteLighting"}],["meta",{"property":"og:title","content":"评论系统和可用性设计"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://cloud.braumace.cn/f/XPjS0/0801_1.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-12-15T09:08:13.000Z"}],["meta",{"property":"article:tag","content":"评论系统"}],["meta",{"property":"article:published_time","content":"2024-08-01T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-12-15T09:08:13.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"评论系统和可用性设计\\",\\"image\\":[\\"https://cloud.braumace.cn/f/XPjS0/0801_1.png\\",\\"https://cloud.braumace.cn/f/xZGFl/0801_2.png\\",\\"https://cloud.braumace.cn/f/vwkFE/0801_3.png\\",\\"https://cloud.braumace.cn/f/APPIE/0801_4.png\\",\\"https://cloud.braumace.cn/f/yg8T1/0801_5.png\\",\\"https://cloud.braumace.cn/f/9X8Ur/0801_6.png\\",\\"https://cloud.braumace.cn/f/w15Ck/0801_7.png\\"],\\"datePublished\\":\\"2024-08-01T00:00:00.000Z\\",\\"dateModified\\":\\"2024-12-15T09:08:13.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"BraumAce\\",\\"url\\":\\"https://blog.braumace.cn/article\\"}]}"]]},"headers":[{"level":2,"title":"存储设计","slug":"存储设计","link":"#存储设计","children":[{"level":3,"title":"数据表设计","slug":"数据表设计","link":"#数据表设计","children":[]},{"level":3,"title":"总结","slug":"总结","link":"#总结","children":[]},{"level":3,"title":"缓存设计","slug":"缓存设计","link":"#缓存设计","children":[]}]},{"level":2,"title":"可用性设计","slug":"可用性设计","link":"#可用性设计","children":[{"level":3,"title":"缓存穿透","slug":"缓存穿透","link":"#缓存穿透","children":[]},{"level":3,"title":"热点","slug":"热点","link":"#热点","children":[]}]}],"git":{"createdTime":1722606585000,"updatedTime":1734253693000,"contributors":[{"name":"BraumAce","email":"1693717911@qq.com","commits":1}]},"readingTime":{"minutes":6.86,"words":2057},"filePathRelative":"architecture/system-design/comment/评论系统存储和可用性设计.md","localizedDate":"2024年8月1日","excerpt":"\\n"}');export{h as comp,d as data};
